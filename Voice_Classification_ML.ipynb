{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3810jvsc74a57bd00349bf72da7b73fc5104051b3f2613547ee96a78053963237f924312f68fab22",
   "display_name": "Python 3.8.10 64-bit ('tf')"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import shutil\n",
    "from tqdm import tqdm\n",
    "from glob import glob\n",
    "import librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                   path    id\n",
       "0  ./data/test/4737.wav  4737\n",
       "1   ./data/test/793.wav   793\n",
       "2  ./data/test/1961.wav  1961\n",
       "3  ./data/test/5574.wav  5574\n",
       "4  ./data/test/1618.wav  1618"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>path</th>\n      <th>id</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>./data/test/4737.wav</td>\n      <td>4737</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>./data/test/793.wav</td>\n      <td>793</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>./data/test/1961.wav</td>\n      <td>1961</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>./data/test/5574.wav</td>\n      <td>5574</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>./data/test/1618.wav</td>\n      <td>1618</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "# glob로 test data의 path를 불러옴. 순서대로 로드되지 않을 경우를 주의\n",
    "# test_ 데이터 프레임을 만들어 나중에 sample_submission과 id를 기준으로 merge시킬 준비\n",
    "\n",
    "def get_id(data):\n",
    "    return int(os.path.split(data)[-1].split(\".\")[0])\n",
    "\n",
    "test_ = pd.DataFrame(index = range(0, 6100), columns = [\"path\", \"id\"])\n",
    "test_[\"path\"] = glob(\"./data/test/*.wav\")\n",
    "test_[\"id\"] = test_[\"path\"].apply(lambda x : get_id(x))\n",
    "\n",
    "test_.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(25520, 32064) float32\n(25520,) int64\n(6100, 32064) float32\n"
     ]
    }
   ],
   "source": [
    "train_x = np.load(\"./npy_data/train_x.npy\")\n",
    "train_y = np.load(\"./npy_data/train_y.npy\")\n",
    "test_x = np.load(\"./npy_data/test_x.npy\")\n",
    "\n",
    "train_x = train_x.reshape((25520, 64 * 501))\n",
    "test_x = test_x.reshape((6100, 64 * 501))\n",
    "\n",
    "print(train_x.shape, train_x.dtype)\n",
    "print(train_y.shape, train_y.dtype)\n",
    "print(test_x.shape, test_x.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "MinMaxScaler()"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(train_x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(20416, 32064)\n(5104, 32064)\n(20416,)\n(5104,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_x, test_x, train_y, test_y = train_test_split(train_x, train_y, test_size=0.2)\n",
    "\n",
    "print(train_x.shape)\n",
    "print(test_x.shape)\n",
    "print(train_y.shape)\n",
    "print(test_y.shape)\n"
   ]
  },
  {
   "source": [
    "# ML MODEL"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/home/hoyun/.conda/envs/tf/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "0.4715909090909091\n"
     ]
    }
   ],
   "source": [
    "# LogisticRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "LR = LogisticRegression()\n",
    "LR.fit(train_x, train_y)\n",
    "pred = LR.predict(test_x)\n",
    "acc = accuracy_score(pred, test_y)\n",
    "print(acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.3906739811912226\n"
     ]
    }
   ],
   "source": [
    "# DecisionTreeClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "DT = DecisionTreeClassifier()\n",
    "DT.fit(train_x, train_y)\n",
    "pred = DT.predict(test_x)\n",
    "acc = accuracy_score(pred, test_y)\n",
    "print(acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.538205329153605\n"
     ]
    }
   ],
   "source": [
    "# RandomForestClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "RF = RandomForestClassifier(n_estimators=100, oob_score=True, random_state=0)\n",
    "RF.fit(train_x, train_y)\n",
    "pred = RF.predict(test_x)\n",
    "acc = accuracy_score(pred, test_y)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.5211598746081505\n"
     ]
    }
   ],
   "source": [
    "# AdaBoostClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "AB = RandomForestClassifier(n_estimators=50)\n",
    "AB.fit(train_x, train_y)\n",
    "pred = AB.predict(test_x)\n",
    "acc = accuracy_score(pred, test_y)\n",
    "print(acc)"
   ]
  }
 ]
}